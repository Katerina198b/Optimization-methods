{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Замятина Екатерина 476 группа"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\min_{x\\in Q} f(x) $$\n",
    "\n",
    "Q - замкнутое выпуклое множество в бесконечномерном линейном пространсте, f(x) - выпуклая негладкая  функция"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Субградиентный метод с двойным усреднением (Subgradient Method with Double SimpleAveraging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Описанный выше метод называется\n",
    "субградиентным методом с двойным\n",
    "усреднением, т.к. в нём применяется как усреднение субградиентов, так и\n",
    "усреднение исходной последовательности (при $α_k ≡ 1$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_t^+= arg\\min_{x \\in Q} {\\frac{1}{A_t}(\\sum_{i=0}^t a_i v(x_i),x) + \\frac{\\gamma}{2A_t} || x - x_0||^2}$$\n",
    "\n",
    "$$ m_t = \\frac{a_{t+1}}{A_{t+1}} \\hspace{10mm} x_{t+1} = (1-m_t)x_t + m_t x_t^+ \\hspace{10mm} \\sum^t_{i=1} a_i = A_t \\hspace{10mm} v(x) \\in \\partial f$$\n",
    "\n",
    "Вся суть метода состоит в том, что мы свели функцию, не обладающую достаточной гладкостью (например модуль), к бесконечно гладкой функции, к которой уже можно применять любые ранее известные методы.\n",
    "\n",
    "Метод сходится как : $f(x_k) - f(x^*) = O(\\frac{1}{\\sqrt{k}})$ при $a_k = 1, \\hspace{10mm} A_t = t +1 \\hspace{10mm} \\gamma_k= \\sqrt{k+1} $\n",
    "\n",
    "Можно немного модифицирвать алгоритм выше и получить субградтиентный метод с простым двойным ускорением\n",
    "$$x_t^+= arg\\min_{x \\in Q} {(\\sum_{i=0}^t v(x_i),x) + \\gamma || x - x_0||^2}$$\n",
    "\n",
    "$$ x_{t+1} = \\dfrac{t+1}{t+2}x_t + \\dfrac{1}{t+2} x_t^+ \\hspace{10mm} v(x) \\in \\partial f$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Заметим, функция гладкая, а значит мы можем гарантировать, что градиент направлен по росту функции, кроме то , если у f(x) Липшивиц градиент,то можно воспользоваться проксимальной функцией для поиска argmin как индикаторной функцией проекции.\n",
    "\n",
    "$$x_{t}^+= arg\\min_{x \\in Q} {(\\sum_{i=0}^t v(x_i),x) + \\gamma || x - x_0||^2} = arg\\min_{x \\in Q} g(x)$$ \n",
    "$$ \\nabla g(x) = \\sum_{i=0}^t v(x_i) + 2\\gamma ( x - x_0) $$\n",
    "$$ x* = \\pi_Q(x_0 - \\dfrac{1}{2\\gamma} \\sum_{i=0}^t v(x_i)) = \\pi_Q(x_0 - \\dfrac{1}{2\\gamma} s_t) $$\n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "METHOD_QUASI_MONOTONE_DEFAULT_GAMMA = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def SGMDoubleSimpleAveraging(oracle, projection_function, dimension=0, num_iterations=100, gamma=METHOD_QUASI_MONOTONE_DEFAULT_GAMMA):\n",
    "\n",
    "    oracle_calls = 0\n",
    "    iteration_number = 0\n",
    "    lambda_k = projection_function(np.zeros(dimension, dtype=float))\n",
    "    s_k = np.zeros(dimension, dtype=float) \n",
    "\n",
    "\n",
    "    while iteration_number < num_iterations:\n",
    "        d_k, diff_d_k = oracle(lambda_k)\n",
    "        oracle_calls += 1\n",
    "       \n",
    "        s_k += diff_d_k\n",
    "        lambda_k_plus = float(1.0)/float(2*gamma*np.sqrt(iteration_number+1)) * s_k\n",
    "        lambda_k_plus = projection_function(lambda_k_plus)\n",
    "\n",
    "        lambda_k = float(iteration_number+1)/float(iteration_number+2)*lambda_k \\\n",
    "                        + float(1.0)/float(iteration_number+2)*lambda_k_plus\n",
    "\n",
    "        iteration_number += 1\n",
    "        \n",
    "    return -d_k, lambda_k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation*}\n",
    "f(x_1,x_2) = \n",
    " \\begin{cases}\n",
    "   5(9x_1^2 +16x_2^2)^{\\frac{1}{2}} & x_1 > |x_2| \\\\\n",
    "   9x_1 + 16|x_2| & x_1 \\le |x_2|\n",
    " \\end{cases}\n",
    "\\end{equation*}\n",
    "  $$ s.t. -3 \\le x_1,x_2 \\le 3$$\n",
    " $$\\min_{x_1,x_2}f(x_1,x_2) = \\max_{\\lambda} \\min_{x_1,x_2,x_3}L(x_1,x_2,x_3) = \\max_{\\lambda} \\min_{x_1,x_2,x_3}f(x_1,x_2,x_3) = \\min_{\\lambda} \\min_{x_1,x_2,x_3}-f(x_1,x_2,x_3)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def oracle(x):\n",
    "\n",
    "    if x[0] > abs(x[1]):\n",
    "        f_x = 5*(9*x[0]**2 + 16*x[1]**2)**(float(1)/float(2))\n",
    "        diff_f_x = np.array([float(9*5*x[0])/np.sqrt(9*x[0]**2 + 16*x[1]**2), \n",
    "                             float(16*5*x[0])/np.sqrt(9*x[0]**2 + 16*x[1]**2)])\n",
    "    else:\n",
    "        f_x = 9*x[0] + 16*abs(x[1])\n",
    "        if x[1] >= 0:\n",
    "            diff_f_x = np.array([9, 16], dtype=float)\n",
    "        else:\n",
    "            diff_f_x = np.array([9, -16], dtype=float)\n",
    "    return  -f_x, -diff_f_x  # return negation to minimize\n",
    "\n",
    "\n",
    "def projection_function(x):\n",
    "\n",
    "    return np.array([min(max(x[0],-3),3), min(max(x[1],-3),3)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-26.023005963338985, array([-2.997003  , -0.05678802]))"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGMDoubleSimpleAveraging(oracle, projection_function, dimension=2, num_iterations=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой пример:\n",
    "    $$\\min_{x}\\sum_{i=1}^k f_i \\max_{s}((a_{is},x) + c_s)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "f = [random.uniform(-100, 100),random.uniform(-100, 100),random.uniform(-100, 100),\\\n",
    "    random.uniform(-100, 100),random.uniform(-100, 100)]\n",
    "a = np.array([[[random.uniform(-100, 100),random.uniform(-100, 100)],[random.uniform(-100, 100),\\\n",
    "    random.uniform(-100, 100)]],[[random.uniform(-100, 100),random.uniform(-100, 100)],\\\n",
    "    [random.uniform(-100, 100),random.uniform(-100, 100)]],[[random.uniform(-100, 100),\\\n",
    "    random.uniform(-100, 100)],[random.uniform(-100, 100),random.uniform(-100, 100)]],\\\n",
    "    [[random.uniform(-100, 100),random.uniform(-100, 100)],[random.uniform(-100, 100),\\\n",
    "    random.uniform(-100, 100)]],[[random.uniform(-100, 100),random.uniform(-100, 100)],\\\n",
    "    [random.uniform(-100, 100),random.uniform(-100, 100)]]])\n",
    "c = [random.uniform(-100, 100),random.uniform(-100, 100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def oracle_2(x):\n",
    "    diff_f_x = [0,0]\n",
    "    f_x = 0\n",
    "    k =0\n",
    "    m =0\n",
    "    maxx_i = [0,0,0,0,0]\n",
    "    maxx = -100000000000;\n",
    "    while(k<5):\n",
    "        while(m<2):\n",
    "            if (a[k][m][0]*x[0] + a[k][m][1]*x[1] - c[m]> maxx):\n",
    "                maxx = a[k][m][0]*x[0] + a[k][m][1]*x[1] - c[m]\n",
    "                maxx_i[k] = m \n",
    "            m = m +1\n",
    "           \n",
    "        f_x =+ f[k]*maxx\n",
    "        k = k +1\n",
    "        m = 0\n",
    "    for i in range(5):\n",
    "        diff_f_x[0] =+ f[i]*a[i][maxx_i[i]][0]\n",
    "        diff_f_x[1] =+ f[i]*a[i][maxx_i[i]][1]\n",
    "    diff_f_x[0] = -diff_f_x[0]\n",
    "    diff_f_x[1] = -diff_f_x[1] \n",
    "    return -f_x, diff_f_x   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-402348986.79427612, array([ 27892.28106219,  58857.42380908]))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SGMDoubleSimpleAveraging(oracle_2, projection_function_2, dimension=2, num_iterations=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def projection_function_2(x):\n",
    "    return x;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
